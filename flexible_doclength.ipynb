{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Model\n",
    "\n",
    "Trying toy model inspired by [Griffiths & Steyvers, 2004](https://doi.org/10.1073/pnas.0307752101)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "- Use `tf.ragged_constant`, i. e. `tf`'s ragged tensor capability to efficiently\n",
    "pad $C$ and $N$ an transform from $C_T$ to $C_{DN_{\\mathrm{max}}}$ or $W_T$ and \n",
    "$W_{DN_{\\mathrm{max}}}$. Construct with `tf.RaggedTensor.from_row_lengths()`.\n",
    "- Use `tf.sparse` to operate with $C_{DN_{\\mathrm{max}}K}$ and $C_{TK}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "tfd = tfp.distributions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from timeit import timeit\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  \n",
    "\n",
    "import topicflow.utils as tp_utils\n",
    "import topicflow.data as tp_data\n",
    "\n",
    "tp_utils = reload(tp_utils)\n",
    "tp_data = reload(tp_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sampling Behaviour of `tfp.Distributions`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [2, 0],\n",
       "       [2, 0],\n",
       "       [2, 0]])"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tfd.Categorical sampling behaviour:\n",
    "probs = tf.constant([[0., 0., 1.], \n",
    "                     [1., 0., 0.]])\n",
    "print(probs.shape)\n",
    "tfd.Categorical(probs=probs).sample(4).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02140409, 0.01427036, 0.9643255 ],\n",
       "       [0.38862276, 0.16176145, 0.44961584]], dtype=float32)"
      ]
     },
     "execution_count": 943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tfd.Dirichlet sampling behaviour:\n",
    "conc = tf.constant([[0.1, 0.1, 0.1], \n",
    "                    [  2.,  2.,  2.]])\n",
    "tfd.Dirichlet(conc).sample().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rightarrow$ Samples come in by row. For Categorical the sample size is flexible. For Dirichlet the sample cise is bounded to the concentrations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting up Topics and Data**\n",
    "\n",
    "### Understand The indices in this Notebook\n",
    "\n",
    "- $K$ is the number of topics \n",
    "- $D$ is the number of documents\n",
    "- $I_d$ is the number of words in document $d$\n",
    "- $N_{\\mathrm{max}}$ is the maximum number of words per doument, i. e. $N_{\\mathrm{max}} = \\max_d \\{I_d\\}$\n",
    "- $T$ is the total number of words, i. e. $T = \\sum_d I_d$\n",
    "- $V$ is the vocabulary size which should be a square of an integer for the visualization purposes of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Specify global parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrtV = 5    # Square Root of the Number of \"Vocabulary\" (must be sqrt such that pictorial interpretation is possible)\n",
    "D     = 1000  # Number of documents\n",
    "N     = 100  \n",
    "V = int(sqrtV**2)\n",
    "K = 2*sqrtV\n",
    "alpha = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Generating Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tp_data.squareLDDocuments(D, sqrtV, N_words_fixed=N, alpha=alpha)\n",
    "Theta, Pi, C_DId, C_DIdK, W_DId = data.extract_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(tf.reduce_max(W_DId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, None, 10])"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_DIdK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics for the Words in Document d=11:\n",
      "tf.Tensor(\n",
      "[8 8 1 8 8 8 3 8 1 1 8 4 0 6 3 1 9 8 8 4 8 1 9 1 7 3 0 3 8 8 4 3 8 9 3 9 6\n",
      " 1 3 8 9 2 3 8 3 8 8 5 9 6 3 1 5 0 0 9 3 1 1 4 3 8 0 9 5 8 1 0 9 0 1 1 3 8\n",
      " 3 3 8 3 0 3 0 7 3 3 0 8 9 8 0 5 9 3 3 7 5 2 0 8 5 0 1 3 5 1 5 0 5 8 5 8 3\n",
      " 9 8 3 8 8 8 3 0 6 3], shape=(121,), dtype=int32)\n",
      "\n",
      "Words in Document d=11:\n",
      "tf.Tensor(\n",
      "[23 18  8 18 18 13 18 23  9  9 18 21  3  1 19  7 19  3 18 20  8  5 19  8\n",
      "  2 18  0 18 13 18 20 18  3 19 16  9 16  9 18 18  9 12 15  8 16  8 23 10\n",
      " 24 21 19  8  5  2  2  9 17  5  5 20 17  8  2 19  0  8  6  3  4  2  8  5\n",
      " 16 23 15 18 18 17  1 18  2  2 18 17  0 13  4  8  0 15 14 16 16 22 20 10\n",
      "  1  8  0  1  5 18  0  5  0  0 20 13 20  3 16  4  3 18  3  3 23 16  4 16\n",
      " 16], shape=(121,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "## To extract topic-word assignments and document-words for a \n",
    "print(\"Topics for the Words in Document d=11:\")\n",
    "print(C_DId[11])\n",
    "print(\"\\nWords in Document d=11:\")\n",
    "print(W_DId[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Checking Shapes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For development purposes:\n",
    "def print_all_shapes():\n",
    "    print(\"Π-Shape (D docs x K topics)\")\n",
    "    print(Pi.shape)\n",
    "    print(\"\\nΘ-Shape (K topic x V vocab)\")\n",
    "    print(Theta.shape)\n",
    "    print(\"\\nC_DIdK-Shape (Topic for each word T=sum_d I_d)\")\n",
    "    print(C_DId.shape)\n",
    "    print(\"\\nC_DIdK-Shape (one-hot for each topic k in {1, K})\")\n",
    "    print(C_DIdK.shape)\n",
    "    print(\"\\nW-Shape (sum_d I_d words)\")\n",
    "    print(W_DId.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Π-Shape (D docs x K topics)\n",
      "(1000, 10)\n",
      "\n",
      "Θ-Shape (K topic x V vocab)\n",
      "(10, 25)\n",
      "\n",
      "C_DIdK-Shape (Topic for each word T=sum_d I_d)\n",
      "(1000, None)\n",
      "\n",
      "C_DIdK-Shape (one-hot for each topic k in {1, K})\n",
      "(1000, None, 10)\n",
      "\n",
      "W-Shape (sum_d I_d words)\n",
      "(1000, None)\n"
     ]
    }
   ],
   "source": [
    "print_all_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = tp_utils.visualize_topics(Theta, 2, int(Theta.shape[0] / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presenting documents [102 435 860 270 106  71 700  20 614 121]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = tp_utils.visualize_random_docs(W_DId, sqrt_V=sqrtV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gibbs Sampler**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **N-Tensor**\n",
    "One efficiency crtitical step is to vectorize \n",
    "$$\n",
    "    n_{dkv} =  \\{i \\, \\vert \\, w_{di} == v \\ \\& \\ c_{idk} ==1\\}\n",
    "$$\n",
    "as much as possible. Due to the fact, that the document lengths are variable there is the choice between looping over the number of documents or padding the documents to a unique length. The padding does not need a word-token, it can be done by padding the $C$ matrix with $0$, therefore it will not affect $N$. Then the counting can be realized by stacking $W$ $K$ times along the last axis to match the shape of $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Multiloop over all Dimensions\n",
    "\n",
    "Mainly for test purposes. Horribly slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiloop_N_tensor(W_DId, C_DIdK, V=V, verbose=False):\n",
    "\n",
    "    ragged = any([x==None for x in W_DId.shape.as_list()])\n",
    "    print(f\"Is ragged? - {ragged}\")\n",
    "\n",
    "    K = C_DIdK.shape[-1]\n",
    "    D = C_DIdK.shape[0]\n",
    "    N_DKV = np.zeros(shape=(D, K, V))\n",
    "\n",
    "    if ragged:\n",
    "        W_DId  = W_DId.to_list() \n",
    "        C_DIdK = C_DIdK.to_list() \n",
    "    else:\n",
    "        W_DId  = W_DId.numpy() \n",
    "        C_DIdK = C_DIdK.numpy() \n",
    "\n",
    "    if verbose:\n",
    "        iterator = tqdm(range(D))\n",
    "    else:\n",
    "        iterator = range(D)\n",
    "    \n",
    "    for d in iterator:\n",
    "        for k in range(K):\n",
    "            for v in range(V):\n",
    "                if ragged:\n",
    "                    zip_it = zip(W_DId[d], np.array(C_DIdK[d])[:, k])\n",
    "                else:\n",
    "                    zip_it = zip(W_DId[d], np.array(C_DIdK[d, :, k]))\n",
    "                for w_di, c_dik in zip_it:\n",
    "                    if w_di == v and c_dik == 1:\n",
    "                        N_DKV[d, k, v] += 1\n",
    "\n",
    "    return N_DKV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test and Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_test1 = multiloop_N_tensor(W_DId, C_DIdK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit multiloop_N_tensor(W_DId, C_DIdK, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Vectorized with Padding using `tf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, None, 10])"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_DIdK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actual n-Tensor\n",
    "@tf.function\n",
    "def tf_N_tensor(W_DId, C_DIdK, V=V):\n",
    "\n",
    "    if any([x==None for x in C_DIdK.shape]):\n",
    "        if C_DIdK.row_splits.dtype != tf.int32:\n",
    "            C_DIdK = C_DIdK.with_row_splits_dtype(tf.int32)\n",
    "\n",
    "    ## Extracting shapes\n",
    "    D = W_DId.shape[0]\n",
    "    K = C_DIdK.shape[-1]\n",
    "    \n",
    "    ## Preparing W-stacking by shifting all entries one \"up\" s. t. v is counted \n",
    "    #  from 1 to V+1 instead from 0 to V. This enables to collapse the \"&\" in the\n",
    "    #  set to be collapsed to a matrix product\n",
    "    Wp1 = W_DId + 1\n",
    "    W_stacked = tf.stack(K*[Wp1], axis=-1)    \n",
    "\n",
    "    ## Elementwise product combines logical & in condition.\n",
    "    #  Choosing int32 as product dtype for efficiency.\n",
    "    C_DIdK_int = tf.cast(C_DIdK, dtype=tf.int32)\n",
    "    C_Dot_W = tf.math.multiply(W_stacked, C_DIdK_int)\n",
    "\n",
    "    ## The v-dimension of N is a one-hot encoding for the vocabulary:\n",
    "    N_DIdKVp1 = tf.one_hot(C_Dot_W, V+1, dtype=tf.int32)\n",
    "\n",
    "    ## Reverting the v-shift by dropping the 0 one-hot dimension\n",
    "    N_DIdKV = N_DIdKVp1[:, :, :, 1:]\n",
    "\n",
    "    ## Summing along v-dimension\n",
    "    N_DKV = tf.reduce_sum(N_DIdKV, axis=1)\n",
    "\n",
    "    ## Turn to float for gibbs sampler\n",
    "    N_DKV = tf.cast(N_DKV, dtype=tf.float32)\n",
    "\n",
    "    return N_DKV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test2 = tf_N_tensor(W_DId, C_DIdK)\n",
    "# np.all(N_test2 == N_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test and Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit tf_N_tensor(W_DId, C_DIdK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For D=1000, V=25 and I_d~100 The tf Version is about a factor 20.2 more efficient than the list version.\n"
     ]
    }
   ],
   "source": [
    "print(f\"For D={D}, V={V} and I_d~{N} The tf Version is about a factor {round(101./5., 1)} more efficient than the list version.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sampling $C$**\n",
    "\n",
    "Sampling $\\Theta$ and $\\Pi$ is not very problematic because they are just dirichlet distributed (below). Sampling $C$ is sampling from \n",
    "$$\n",
    "    p(C\\vert \\Theta, \\Pi, W)=\\prod_{d=1}^D \\prod_{i=1}^{I_d} \\frac{\\prod_{k=1}^K \\left(\\pi_{dk}\\theta_{kw_{di}}\\right)^{c_{dik}}}{\\sum_{k'=1}^K\\left(\\pi_{dk'}\\theta_{k'w_{di}}\\right)}\n",
    "$$ \n",
    "which is a categorical distribution. The dependence of $I_d$ is somewhat entangled in the $w_{di}$ index of $\\Theta_{kw_{di}}$. A fully vectorized solution without loop over $D$ therefore again needs padding.\n",
    "\n",
    "https://youtu.be/z2q7LhsnWNg?t=3878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Nmax = int(tf.reduce_max(W_DId.nested_row_lengths()[0]))\n",
    "except:\n",
    "    Nmax = N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorized C-Sampling (W_DNmax must be padded!)\n",
    "@tf.function\n",
    "def sample_C(Theta, Pi, W_DId, Nmax: int):\n",
    "    ## Extracting shapes\n",
    "    ragged = any([x==None for x in W_DId.shape])\n",
    "    K = Pi.shape[-1]\n",
    "    V = Theta.shape[1]\n",
    "\n",
    "    # Padding\n",
    "    if ragged:\n",
    "        W_DNmax = W_DId.to_tensor(0)\n",
    "        mask = W_DId.to_tensor(V+1) != V+1\n",
    "    if not ragged:\n",
    "        W_DNmax = W_DId\n",
    "\n",
    "    ## Numerator\n",
    "    Theta_DNmaxK = tf.gather(tf.transpose(Theta), W_DNmax) \n",
    "    Pi_block  = tf.stack(Nmax * [Pi], axis=1)\n",
    "    numerator = tf.math.multiply(Pi_block, Theta_DNmaxK)\n",
    "\n",
    "    ## Dividing by Denominator\n",
    "    # denominator = tf.reduce_sum(numerator, axis=-1)\n",
    "\n",
    "    ## Sampling\n",
    "    C_DNmax_dist = tfd.Categorical(probs=numerator)\n",
    "    C_DNmax      = C_DNmax_dist.sample()\n",
    "    if ragged:\n",
    "        C_DId = tf.ragged.boolean_mask(C_DNmax, mask)\n",
    "        C_DId = C_DId.with_row_splits_dtype(tf.int32)\n",
    "    if not ragged:\n",
    "        C_DId = C_DNmax\n",
    "\n",
    "    # ## One-Hot-Encoding\n",
    "    C_DIdK = tf.one_hot(C_DId, K, axis=-1)\n",
    "\n",
    "    return C_DIdK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, None, 10])"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_C(Theta, Pi, W_DId, Nmax).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W_temp      = W_DId.to_tensor(0)\n",
    "# mask_temp   = W_DId.to_tensor(V+1) != V+1\n",
    "# W_temp      = W_temp.numpy()\n",
    "# Pi_temp     = tf.stack(Nmax * [Pi], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theta_1 = tf.gather(tf.transpose(Theta), W_temp)\n",
    "# numerator_1 = tf.math.multiply(Pi_temp, Theta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Tets purposes: Calculate Theta_KW in loop\n",
    "# Theta_DNmaxK_loop = np.zeros(shape=(D, Nmax, K))\n",
    "# for d in tqdm(range(D)):\n",
    "#     for i in range(Nmax):\n",
    "#         for k in range(K):\n",
    "#             Theta_DNmaxK_loop[d, i, k] = Theta[k, W_temp[d, i]]\n",
    "\n",
    "# assert np.all(Theta_DNmaxK_loop == Theta_1)\n",
    "# numerator_loop = tf.math.multiply(Pi_temp, Theta_DNmaxK_loop)\n",
    "# assert np.all(numerator_loop == numerator_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_temp_dist = tfd.Categorical(probs=numerator_1)\n",
    "# C_temp      = C_temp_dist.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sampling $\\Theta$ and $\\Pi$**\n",
    "\n",
    "Sampling $\\Theta$ and $\\Pi$:\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        p(\\Theta\\vert C, W) &= \\prod_{k=1}^K \\mathcal D(\\theta_k; \\ \\beta_{k:} + n_{\\cdot k:}) \\\\\n",
    "        p(\\Pi\\vert C, W)    &= \\prod_{d=1}^D \\mathcal D(\\pi_d; \\ \\alpha_{d:} + n_{d:\\cdot}) \\, .\n",
    "    \\end{align*}\n",
    "$$\n",
    "$\\Theta$ and $\\Pi$ are neither dependent on the number of words per document nor do they have an $I_d$ dimension. Therefore it is much easier to sample them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def sample_Theta(N_DKV, beta):\n",
    "    dist_Theta = tfd.Dirichlet(beta + tf.reduce_sum(N_DKV, axis=0))\n",
    "    Theta      = dist_Theta.sample()\n",
    "    return Theta\n",
    "\n",
    "@tf.function\n",
    "def sample_Pi(N_DKV, alpha):\n",
    "    dist_Pi = tfd.Dirichlet(alpha + tf.reduce_sum(N_DKV, axis=-1))\n",
    "    Pi      = dist_Pi.sample()\n",
    "    return Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Random Initialization of Prior Alpha and Beta.\n",
    "# #  They do not acutally matter much but could be optimized by Type II MAP or MLE.\n",
    "# beta  = tf.constant(np.random.normal(size=(K, V)), dtype=tf.float32)\n",
    "# alpha = tf.constant(np.random.normal(size=(D, K)), dtype=tf.float32)\n",
    "\n",
    "# ## Calculate one N_DKV for test purposes\n",
    "# W_DNmax, C_DNmaxK = padd_CW(W_T, C_TK, N_idx)\n",
    "# N_test = tf_N_tensor(W_DNmax, C_DNmaxK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Theta = sample_Theta(N_test, beta)\n",
    "# test_Pi    = sample_Pi(N_test, alpha)\n",
    "\n",
    "# assert test_Theta.shape == Theta.shape\n",
    "# assert test_Pi.shape == Pi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Main Loop**\n",
    "\n",
    "Later: Add `@tf.function` decorator to `drop_pad_C` and replace `padd_CW` with `tf_padd_CW` in main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmax = int(np.max(data.get_doc_lengths()))\n",
    "Ntotal = int(np.sum(data.get_doc_lengths()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_iter = 200\n",
    "\n",
    "C_Ntotal  = tf.constant(np.random.randint(0, K, size=Ntotal))\n",
    "C_DId_ = tf.RaggedTensor.from_row_lengths(\n",
    "    values=C_Ntotal,\n",
    "    row_lengths=W_DId.nested_row_lengths()[0])\n",
    "C_DIdK_ = tf.one_hot(C_DId_, K, axis=-1)\n",
    "\n",
    "beta  = tf.ones(shape=(K, V), dtype=tf.float32)\n",
    "alpha = tf.ones(shape=(D, K), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `W_T` and `N_idx` are fixed since they are observable from the data and do therefore not have to be initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First iteration takes a while brcause of tracing of `drop_pad_C` and `tf_pad_CW`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data.uniform_doclengths:\n",
    "    C_DIdK_ = C_DIdK_.to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:08<00:00, 22.33it/s]\n"
     ]
    }
   ],
   "source": [
    "Theta_store = []\n",
    "for iter in tqdm(range(N_iter)):\n",
    "\n",
    "    ## Calculate N_DKV_ from W_DNmax and C_DNmaxK\n",
    "    N_DKV_ = tf_N_tensor(W_DId, C_DIdK_)\n",
    "    \n",
    "    ## Sample Theta_ and Pi_ from N_DKV_ and priors\n",
    "    Theta_ = sample_Theta(N_DKV_, beta)\n",
    "    Pi_    = sample_Pi(N_DKV_, alpha)\n",
    "\n",
    "    ## Sample C_DNmaxK from Theta, Pi and N_DKV_\n",
    "    C_DIdK_ = sample_C(Theta_, Pi_, W_DId, Nmax)\n",
    "    \n",
    "    Theta_store.append(Theta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta_store = tf.stack(Theta_store, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = tp_utils.visualize_topics(Theta_, 2, int(Theta.shape[0] / 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tfa-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b28dcc1f87ebe436630d7ecff3a3c61833e6c22febb81b1e7cd0d34da649d2b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

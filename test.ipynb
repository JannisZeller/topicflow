{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Model\n",
    "\n",
    "Trying toy model inspired by [Griffiths & Steyvers, 2004](https://doi.org/10.1073/pnas.0307752101)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "tfd = tfp.distributions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Topics and Data\n",
    "\n",
    "1. Specify global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of Topics\n",
    "K = 10\n",
    "\n",
    "## Square Root of the Number of \"Vocabulary\" (must be sqrt such that pictorial interpretation is possible)\n",
    "sqrtV = 5\n",
    "\n",
    "## Number of words per document\n",
    "N = 100\n",
    "\n",
    "## Number of documents\n",
    "D = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define Topic-Word relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word grid\n",
    "V_grid = np.reshape(np.arange(0, sqrtV**2), newshape=(sqrtV, sqrtV))\n",
    "\n",
    "## Topic-Word Distribution\n",
    "#  Words belonging to a topic are rows and columns\n",
    "Theta_idx = [row for row in V_grid] + [col for col in V_grid.T]\n",
    "Theta = np.zeros((K, sqrtV**2))\n",
    "for k, idx in enumerate(Theta_idx):\n",
    "    Theta[k, idx] = 1. / sqrtV\n",
    "\n",
    "## Document topic prior\n",
    "Alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2, 0.2, 0.2, 0.2, 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0.2, 0.2, 0.2, 0.2, 0.2, 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.2, 0.2, 0.2,\n",
       "        0.2, 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0.2, 0.2, 0.2, 0.2, 0.2, 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "       [0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. ,\n",
       "        0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. ,\n",
       "        0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2,\n",
       "        0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. ,\n",
       "        0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. ,\n",
       "        0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Topic-Word Distibution is omitted because Theta is fixed\n",
    "\n",
    "## Document-Topic Distribution\n",
    "dist_Pi = tfd.Dirichlet(K*[Alpha])\n",
    "Pi      = dist_Pi.sample(D)\n",
    "\n",
    "## Topic Assignments of word c_{dik} of word w_{di}\n",
    "dist_C    = tfd.Categorical(probs=Pi)\n",
    "C         = tf.reshape(dist_C.sample(N), shape=(D, -1)) ## Its more efficient to reshape before converting to one_hot vectors\n",
    "C_one_hot = tf.one_hot(C, depth=K, axis=-1)\n",
    "assert tf.reduce_all(tf.reduce_sum(C_one_hot, axis=-1) == 1)\n",
    "\n",
    "## Draw words w_{di}\n",
    "dist_W = tfd.Categorical(probs=Theta)\n",
    "W      = dist_W.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 4,  5, 10, 17, 21, 10, 11, 17, 23, 19])>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
       "array([3, 6, 8, 0, 7, 3, 8, 1, 8, 5, 9, 0, 3, 0, 3, 1, 6, 7, 4, 6, 3, 4,\n",
       "       6, 3, 5, 9, 5, 7, 2, 1, 2, 9, 4, 0, 6, 3, 8, 4, 6, 8, 1, 9, 2, 2,\n",
       "       1, 9, 2, 7, 3, 5, 2, 2, 0, 4, 4, 8, 1, 9, 0, 3, 1, 3, 8, 4, 3, 3,\n",
       "       4, 9, 0, 1, 1, 4, 7, 6, 7, 2, 0, 9, 9, 2, 9, 1, 8, 1, 1, 8, 7, 6,\n",
       "       5, 5, 3, 0, 1, 3, 9, 3, 6, 3, 1, 5])>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_one_hot[0, :3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 25), dtype=float64, numpy=\n",
       "array([[0.2, 0.2, 0.2, 0.2, 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0.2, 0.2, 0.2, 0.2, 0.2, 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.2, 0.2, 0.2,\n",
       "        0.2, 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0.2, 0.2, 0.2, 0.2, 0.2, 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "       [0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. ,\n",
       "        0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. ,\n",
       "        0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2,\n",
       "        0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. ,\n",
       "        0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. ,\n",
       "        0. , 0.2, 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0.2]])>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('tf-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1db6d0bc92fe3ce7d77d39f639140e85f631bb46e23eab36cb8d5c891c4f061"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

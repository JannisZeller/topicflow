{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Model\n",
    "\n",
    "Trying toy model inspired by [Griffiths & Steyvers, 2004](https://doi.org/10.1073/pnas.0307752101)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "tfd = tfp.distributions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Topics and Data\n",
    "\n",
    "1. Specify global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of Topics\n",
    "K = 10\n",
    "\n",
    "## Square Root of the Number of \"Vocabulary\" (must be sqrt such that pictorial interpretation is possible)\n",
    "sqrtV = 5\n",
    "\n",
    "## Number of words per document\n",
    "N = 100\n",
    "\n",
    "## Number of documents\n",
    "D = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define Topic-Word relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word grid\n",
    "V_grid = np.reshape(np.arange(0, sqrtV**2), newshape=(sqrtV, sqrtV))\n",
    "\n",
    "## Topic-Word Distribution\n",
    "#  Words belonging to a topic are rows and columns\n",
    "Theta_idx = [row for row in V_grid] + [col for col in V_grid.T]\n",
    "Theta = np.zeros((K, sqrtV**2))\n",
    "for k, idx in enumerate(Theta_idx):\n",
    "    Theta[k, idx] = 1. / sqrtV\n",
    "\n",
    "## Document topic prior\n",
    "Alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 100])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Topic-Word Distibution is omitted because Theta is fixed\n",
    "\n",
    "## Document-Topic Distribution\n",
    "dist_Pi = tfd.Dirichlet(K*[Alpha])\n",
    "Pi      = dist_Pi.sample(D)\n",
    "\n",
    "## Topic Assignments of word c_{dik} of word w_{di}\n",
    "dist_C    = tfd.Categorical(probs=Pi)\n",
    "C         = tf.reshape(dist_C.sample(N), shape=(D, -1)) ## Its more efficient to reshape before converting to one_hot vectors\n",
    "C_one_hot = tf.one_hot(C, depth=K, axis=-1)\n",
    "assert tf.reduce_all(tf.reduce_sum(C_one_hot, axis=-1) == 1)\n",
    "\n",
    "## Draw words w_{di}\n",
    "dist_W = tfd.Categorical(Theta[C, :])\n",
    "W = dist_W.sample()\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n",
      "(1000, 100)\n",
      "(1000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(Pi.shape)\n",
    "print(C.shape)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_img(arr, sqrtV=5):\n",
    "    vals = dict(zip(*np.unique(arr, return_counts=True)))\n",
    "    img = []\n",
    "\n",
    "    for i in range(sqrtV**2):\n",
    "        if i in vals:\n",
    "            img.append(vals[i])\n",
    "        else:\n",
    "            img.append(0)\n",
    "\n",
    "    img = np.array(img).reshape(sqrtV, sqrtV)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1767590c6a0>"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(format_to_img(W[10]), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_tensor(W, C_one_hot, V=25):\n",
    "    W = W.numpy()\n",
    "    C_one_hot = C_one_hot.numpy()\n",
    "    n = np.zeros(shape=(C_one_hot.shape[0], C_one_hot.shape[2], V))\n",
    "    for v in range(V):\n",
    "        # print(v)\n",
    "        for i in range(C_one_hot.shape[1]):\n",
    "            for d in range(C_one_hot.shape[0]):\n",
    "                for k in range(C_one_hot.shape[2]):\n",
    "                    if W[d, i] == v and C_one_hot[d, i, k] == 1:\n",
    "                        n[d, k, v] += 1\n",
    "    return n\n",
    "\n",
    "@tf.function\n",
    "def tf_N_tensor(W, C_one_hot, V=25):\n",
    "    \n",
    "    N_tensor = tf.Variable(tf.zeros(shape=(C_one_hot.shape[0], C_one_hot.shape[2], V)))\n",
    "\n",
    "    # W = tf.cast(W, dtype=tf.float32) + 1. ## Adding 1 shifting vocab to 1:26, s. t. vectorized removal is possible by product\n",
    "    # for k in range(C_one_hot.shape[-1]):\n",
    "    #     temp = W * C_one_hot[:, :, k]\n",
    "    #     for v in range(1, V+1):\n",
    "    #         if temp == v:\n",
    "    #             N_tensor\n",
    "\n",
    "    for v in range(V):\n",
    "        # print(v)\n",
    "        for i in range(C_one_hot.shape[1]):\n",
    "            for d in range(C_one_hot.shape[0]):\n",
    "                for k in range(C_one_hot.shape[2]):\n",
    "                    if W[d, i] == v and C_one_hot[d, i, k] == 1:\n",
    "                        N_tensor[d, k, v].assign(1.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 100), dtype=int32, numpy=\n",
       "array([[12, 10, 22, ..., 19, 14, 16],\n",
       "       [18, 16,  8, ..., 17,  3, 14],\n",
       "       [10, 18,  4, ...,  3, 13,  0],\n",
       "       ...,\n",
       "       [13,  8, 19, ..., 16,  1, 21],\n",
       "       [10, 10,  3, ..., 11, 19, 21],\n",
       "       [10, 12, 10, ..., 24, 18, 23]])>"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_iter = 100\n",
    "Theta_store = []\n",
    "W_ = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0  = np.random.randint(0, 10,  size=(D, N))\n",
    "C0_one_hot = tf.one_hot(C0, depth=K, axis=-1)\n",
    "\n",
    "alpha0 = np.random.randint(0, 10,  size=(D, N))\n",
    "\n",
    "beta0 = np.random.normal(size=(D, K))\n",
    "\n",
    "\n",
    "# Pi0 = np.random.normal(size=(D, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 100, 10])"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C0_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 100), dtype=float32, numpy=\n",
       "array([[ 0.,  0.,  0., ..., 20.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  4.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  4., ...,  0.,  0.,  0.],\n",
       "       [ 0., 13.,  0., ...,  0.,  0.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = tf.cast(W_, dtype=tf.float32) + 1.\n",
    "W1 * C_one_hot[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 1., ..., 0., 0., 2.],\n",
       "        [0., 0., 0., ..., 0., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 1., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 2.],\n",
       "        [1., 1., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., ..., 3., 0., 1.],\n",
       "        [1., 0., 0., ..., 1., 0., 0.],\n",
       "        [1., 2., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 1., 0., 0.],\n",
       "        [0., 1., 1., ..., 1., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 2., 0., ..., 0., 1., 0.],\n",
       "        [1., 1., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 1., ..., 1., 0., 2.],\n",
       "        ...,\n",
       "        [0., 0., 2., ..., 0., 0., 0.],\n",
       "        [1., 1., 2., ..., 0., 0., 0.],\n",
       "        [1., 0., 1., ..., 0., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 1., ..., 1., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 0., 0., 1.],\n",
       "        [0., 1., 0., ..., 0., 0., 1.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 1., ..., 0., 2., 2.],\n",
       "        [1., 0., 0., ..., 0., 1., 1.],\n",
       "        [1., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 2., 2.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 1., 1., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tensor(W_, C0_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(N_iter):\n",
    "    Ndkv = \n",
    "    Theta_it = tfd.Dirichlet()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tfa-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b28dcc1f87ebe436630d7ecff3a3c61833e6c22febb81b1e7cd0d34da649d2b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
